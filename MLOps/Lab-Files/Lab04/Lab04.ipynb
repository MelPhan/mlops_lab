{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "# # Import Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Wine Quality dataset\n",
    "data = pd.read_csv('winequality-red.csv')\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "# Display information about the dataset\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the target variable\n",
    "sns.countplot(x='quality', data=data)\n",
    "plt.title('Distribution of Wine Quality Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of important features\n",
    "features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'alcohol']\n",
    "plt.figure(figsize=(14, 8))\n",
    "for i, feature in enumerate(features, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.histplot(data[feature], kde=True)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot to visualize relationships between features and the target\n",
    "sns.pairplot(data, diag_kind='kde', hue='quality', markers='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 2\n",
    "# Feature Engineering: Create acidity_ratio\n",
    "data['acidity_ratio'] = data['fixed acidity'] / data['volatile acidity']\n",
    "# Display the first few rows to confirm the new feature\n",
    "print(data[['fixed acidity', 'volatile acidity', 'acidity_ratio']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numeric features to scale\n",
    "numeric_features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'acidity_ratio']\n",
    "\n",
    "# Apply StandardScaler to numeric features\n",
    "scaler = StandardScaler()\n",
    "data[numeric_features] = scaler.fit_transform(data[numeric_features])\n",
    "\n",
    "# Display scaled features\n",
    "print(data[numeric_features].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training set shape:\", X_train.shape, f\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 3\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Function to evaluate the models\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Function to print the confusion matrix\n",
    "def print_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "# Evaluate the Logistic Regression model\n",
    "lr_accuracy, lr_precision, lr_recall, lr_f1 = evaluate_model(y_test, lr_predictions)\n",
    "print(f\"Logistic Regression - Accuracy: {lr_accuracy:.2f}, Precision: {lr_precision:.2f}, Recall: {lr_recall:.2f}, F1 Score: {lr_f1:.2f}\")\n",
    "# Confusion matrix\n",
    "print_confusion_matrix(y_test, lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "# Train the model\n",
    "dt_model.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "# Evaluate the Decision Tree model\n",
    "dt_accuracy, dt_precision, dt_recall, dt_f1 = evaluate_model(y_test, dt_predictions)\n",
    "print(f\"Decision Tree - Accuracy: {dt_accuracy:.2f}, Precision: {dt_precision:.2f}, Recall: {dt_recall:.2f}, F1 Score: {dt_f1:.2f}\")\n",
    "# Confusion matrix\n",
    "print_confusion_matrix(y_test, dt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "# Evaluate the Random Forest model\n",
    "rf_accuracy, rf_precision, rf_recall, rf_f1 = evaluate_model(y_test, rf_predictions)\n",
    "print(f\"Random Forest - Accuracy: {rf_accuracy:.2f}, Precision: {rf_precision:.2f}, Recall: {rf_recall:.2f}, F1 Score: {rf_f1:.2f}\")\n",
    "# Confusion matrix\n",
    "print_confusion_matrix(y_test, rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "# Train the model\n",
    "nb_model.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "# Evaluate the Naive Bayes model\n",
    "nb_accuracy, nb_precision, nb_recall, nb_f1 = evaluate_model(y_test, nb_predictions)\n",
    "print(f\"Naive Bayes - Accuracy: {nb_accuracy:.2f}, Precision: {nb_precision:.2f}, Recall: {nb_recall:.2f}, F1 Score: {nb_f1:.2f}\")\n",
    "# Confusion matrix\n",
    "print_confusion_matrix(y_test, nb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize SVM\n",
    "svm_model = SVC(kernel='rbf', random_state=42)\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "# Evaluate the SVM model\n",
    "svm_accuracy, svm_precision, svm_recall, svm_f1 = evaluate_model(y_test, svm_predictions)\n",
    "print(f\"SVM - Accuracy: {svm_accuracy:.2f}, Precision: {svm_precision:.2f}, Recall: {svm_recall:.2f}, F1 Score: {svm_f1:.2f}\")\n",
    "# Confusion matrix\n",
    "print_confusion_matrix(y_test, svm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize KNN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "# Evaluate the KNN model\n",
    "knn_accuracy, knn_precision, knn_recall, knn_f1 = evaluate_model(y_test, knn_predictions)\n",
    "print(f\"KNN - Accuracy: {knn_accuracy:.2f}, Precision: {knn_precision:.2f}, Recall: {knn_recall:.2f}, F1 Score: {knn_f1:.2f}\")\n",
    "# Confusion matrix\n",
    "print_confusion_matrix(y_test, knn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "# Train the model\n",
    "gb_model.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "gb_predictions = gb_model.predict(X_test)\n",
    "# Evaluate the Gradient Boosting model\n",
    "gb_accuracy, gb_precision, gb_recall, gb_f1 = evaluate_model(y_test, gb_predictions)\n",
    "print(f\"Gradient Boosting - Accuracy: {gb_accuracy:.2f}, Precision: {gb_precision:.2f}, Recall: {gb_recall:.2f}, F1 Score: {gb_f1:.2f}\")\n",
    "# Confusion matrix\n",
    "print_confusion_matrix(y_test, gb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 4\n",
    "# Compare model performance\n",
    "results = {\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Naive Bayes', 'SVM', 'KNN', 'Gradient Boosting'],\n",
    "    'Accuracy': [lr_accuracy, dt_accuracy, rf_accuracy, nb_accuracy, svm_accuracy, knn_accuracy, gb_accuracy],\n",
    "    'Precision': [lr_precision, dt_precision, rf_precision, nb_precision, svm_precision, knn_precision, gb_precision],\n",
    "    'Recall': [lr_recall, dt_recall, rf_recall, nb_recall, svm_recall, knn_recall, gb_recall],\n",
    "    'F1 Score': [lr_f1, dt_f1, rf_f1, nb_f1, svm_f1, knn_f1, gb_f1]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
